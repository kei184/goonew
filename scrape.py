import os
import time
import tempfile
import traceback
import re
from datetime import datetime

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By

import requests
from bs4 import BeautifulSoup

import gspread
from oauth2client.service_account import ServiceAccountCredentials

# === 1. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆè¨­å®š ===
SPREADSHEET_ID = '1LpduIjFPimgUX6g1j5cfLnMT6OayfA5un3it2Z5rwuE'
SHEET_NAME = 'æ–°ç€ç‰©ä»¶'

# === 2. Google APIè¨­å®š ===
GOOGLE_API_KEY = os.environ['GOOGLE_API_KEY']
GOOGLE_CSE_ID = os.environ['GOOGLE_CSE_ID']

# === 3. èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ ===
def create_credentials_file():
    with tempfile.NamedTemporaryFile(delete=False, suffix=".json") as tmp:
        tmp.write(os.environ['GOOGLE_CREDENTIALS_JSON'].encode())
        return tmp.name

# === 4. gooã‹ã‚‰ç‰©ä»¶ãƒªãƒ³ã‚¯ã‚’å–å¾— ===
def fetch_property_names():
    options = Options()
    options.binary_location = "/usr/bin/google-chrome"
    options.add_argument('--headless=new')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--window-size=1920,1080')

    service = Service("/usr/bin/chromedriver")
    driver = webdriver.Chrome(service=service, options=options)
    driver.get("https://house.goo.ne.jp/buy/bm/")
    time.sleep(5)

    elems = driver.find_elements(By.CSS_SELECTOR, "ul.bxslider li a")
    links = [a.get_attribute('href') for a in elems if '/buy/bm/detail/' in a.get_attribute('href')]
    driver.quit()

    names = []
    for url in links:
        full = url if url.startswith('http') else 'https://house.goo.ne.jp' + url
        try:
            res = requests.get(full, timeout=10)
            if res.status_code != 200:
                continue
            soup = BeautifulSoup(res.text, 'html.parser')
            title = soup.title.text.strip() if soup.title else ''
            title = re.sub(r'ã€[^ã€‘]+ã€‘\s*', '', title)
            title = re.sub(r'ï¼ˆä¾¡æ ¼ãƒ»é–“å–ã‚Šï¼‰.*$', '', title)
            clean = title.strip()
            if clean and 'gooä½å®…ãƒ»ä¸å‹•ç”£' not in clean:
                names.append(clean)
        except Exception as e:
            print(f"âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: {full} ({e})")
            continue

    unique = list(dict.fromkeys(names))
    print(f"âœ… å–å¾—æ¸ˆã¿ç‰©ä»¶ï¼ˆé‡è¤‡é™¤å»ï¼‰: {len(unique)} ä»¶")
    for name in unique:
        print("ãƒ»", name)
    return unique

# === 5. Googleæ¤œç´¢ã§å…¬å¼URLã‚’å–å¾—ï¼ˆæœ€å¤§3å›è©¦è¡Œï¼‰===
def get_official_url(query):
    for attempt in range(3):
        try:
            search_url = f"https://www.googleapis.com/customsearch/v1?q={query}&key={GOOGLE_API_KEY}&cx={GOOGLE_CSE_ID}&num=1"
            res = requests.get(search_url)
            if res.status_code == 429:
                wait = 10 + 5 * attempt
                print(f"âš ï¸ APIåˆ¶é™ä¸­ï¼ˆ{res.status_code}ï¼‰: å¾…æ©Ÿ{wait}ç§’")
                time.sleep(wait)
                continue
            res.raise_for_status()
            items = res.json().get('items', [])
            for item in items:
                link = item.get('link', '')
                if any(domain in link for domain in ['.co.jp', '.jp']) and not 'suumo' in link:
                    return link
            return items[0]['link'] if items else ''
        except Exception as e:
            print(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            time.sleep(2)
    return ''

# === 6. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¸è¨˜éŒ² ===
def write_to_sheet(names, cred_path):
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_name(cred_path, scope)
    client = gspread.authorize(creds)
    sheet = client.open_by_key(SPREADSHEET_ID).worksheet(SHEET_NAME)

    existing_names = sheet.col_values(2)[1:]  # Båˆ—ï¼ˆç‰©ä»¶åï¼‰
    existing_urls = sheet.col_values(3)[1:]   # Cåˆ—ï¼ˆURLï¼‰
    today = datetime.now().strftime('%Y/%m/%d')
    new_count = 0

    for name in names:
        if name in existing_names:
            idx = existing_names.index(name)
            if existing_urls[idx].strip():
                print(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¢ã«URLã‚ã‚Šï¼‰: {name}")
                continue

        url = get_official_url(name)
        if name in existing_names:
            row_num = existing_names.index(name) + 2
            sheet.update_cell(row_num, 3, url)
            print(f"ğŸ”„ URLã®ã¿æ›´æ–°: {name}")
        else:
            sheet.append_row([today, name, url])
            print(f"â• æ–°è¦è¿½åŠ : {name}")
            new_count += 1
        time.sleep(1.5)

    print(f"âœ… å®Œäº†ã€‚æ–°è¦ {new_count} ä»¶ã‚’è¿½åŠ ")

# === 7. ãƒ¡ã‚¤ãƒ³å‡¦ç† ===
def main():
    try:
        cred = create_credentials_file()
        names = fetch_property_names()
        if not names:
            print("âŒ ç‰©ä»¶ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        write_to_sheet(names, cred)
    except Exception:
        print("âŒ å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼:")
        traceback.print_exc()

if __name__ == "__main__":
    main()
