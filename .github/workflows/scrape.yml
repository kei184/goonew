name: Scrape goo properties

on:
  # schedule:  # 無効化: 日次スクレイピング実行(daily_scrape.yml)に統合
  #   - cron: '0 1 * * *'
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest

    env:
      GOOGLE_CREDENTIALS_JSON: ${{ secrets.GOOGLE_CREDENTIALS_JSON }}
      GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
      GOOGLE_CSE_ID: ${{ secrets.GOOGLE_CSE_ID }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies and Google Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y wget curl unzip jq fonts-liberation libu2f-udev

          # Google Chrome のインストール
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo apt-get install -y ./google-chrome-stable_current_amd64.deb

          # Python ライブラリのインストール
          pip install -r requirements.txt

      - name: Install matching ChromeDriver
        run: |
          CHROME_VERSION=$(google-chrome --version | grep -oP '\d+\.\d+\.\d+\.\d+')
          echo "Detected Chrome version: $CHROME_VERSION"

          CHROME_MAJOR_VERSION=$(echo "$CHROME_VERSION" | cut -d. -f1)
          echo "Detected Chrome Major Version: $CHROME_MAJOR_VERSION"

          DRIVER_URL=$(curl -s "https://googlechromelabs.github.io/chrome-for-testing/latest-versions-per-milestone-with-downloads.json" \
            | jq -r --arg ver "$CHROME_MAJOR_VERSION" '.milestones[$ver].downloads.chromedriver[] | select(.platform == "linux64") | .url')

          if [ -z "$DRIVER_URL" ]; then
            echo "❌ ChromeDriver URL が見つかりません"
            exit 1
          fi

          echo "✅ Downloading ChromeDriver from: $DRIVER_URL"
          curl -sSL "$DRIVER_URL" -o chromedriver.zip
          unzip chromedriver.zip
          sudo mv chromedriver-linux64/chromedriver /usr/bin/chromedriver
          sudo chmod +x /usr/bin/chromedriver

      - name: Run scraper
        run: python scrape.py
